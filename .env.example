# =============================================================================
# cc-plugin-eval Environment Configuration
# =============================================================================
#
# Copy this file to .env and fill in your values:
#   cp .env.example .env
#
# The .env file is gitignored and will not be committed.
# =============================================================================

# -----------------------------------------------------------------------------
# LLM Provider Selection (Stages 2 & 4 only)
# -----------------------------------------------------------------------------
# Controls which LLM provider is used for scenario generation and evaluation.
# Stage 3 (execution) always uses the Claude Agent SDK regardless of this setting.
#
# Auto-detection priority (if LLM_PROVIDER is not set):
#   1. GEMINI_API_KEY present → gemini (free tier, recommended)
#   2. ANTHROPIC_API_KEY present → anthropic (costs money)
#   3. fallback → ollama (local, requires Ollama running)
#
# Supported values: anthropic, gemini, ollama
# LLM_PROVIDER=gemini

# -----------------------------------------------------------------------------
# Option A: Gemini API Key (recommended - free tier)
# -----------------------------------------------------------------------------
# Get yours at: https://aistudio.google.com/apikey
# Free tier: 1,000 requests/day, 15 requests/minute
# GEMINI_API_KEY=AIza...

# -----------------------------------------------------------------------------
# Option B: Anthropic API Key (paid)
# -----------------------------------------------------------------------------
# Get yours at: https://console.anthropic.com/settings/keys
# ANTHROPIC_API_KEY=sk-ant-api03-...

# -----------------------------------------------------------------------------
# Option C: Ollama (local, no API key needed)
# -----------------------------------------------------------------------------
# Requires Ollama running locally: https://ollama.com
# Default: http://localhost:11434
# OLLAMA_BASE_URL=http://localhost:11434

# -----------------------------------------------------------------------------
# Optional: Custom Anthropic API Endpoint (Stages 2 & 4 only)
# -----------------------------------------------------------------------------
# Uncomment to use a proxy or enterprise endpoint.
# Note: This affects the Anthropic SDK used in generation (Stage 2) and
# evaluation (Stage 4). Stage 3 execution uses the Agent SDK which may
# have different configuration.
# ANTHROPIC_BASE_URL=https://api.anthropic.com
